{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9601f442-d112-4ec1-a10f-18f658e4365f",
   "metadata": {},
   "source": [
    "# 机器学习与深度学习 第二次作业\n",
    "**常响 3022210027**\n",
    "本项目地址：\n",
    "## 任务概要\n",
    "### 环境\n",
    "- Ubuntu LTS 24.04\n",
    "- GPU/Driver：4090/560.35.03\n",
    "- Cuda: 12.6\n",
    "- Pytorch: 2.5.1\n",
    "\n",
    "### 任务概要\n",
    "1. 在两个建议的数据集上微调模型（LeNet-5）的架构，并观察模型结果\n",
    "2. 在两个建议的数据集上微调模型（LeNet-5）的归一化方法与Batch-size，并观察模型结果\n",
    "3. 分析不同优化方法下的模型训练结果\n",
    "4. 尝试两种视觉注意力机制，并比较不同注意力机制的识别精度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951aae98-da69-4622-8060-587e65fd8dd7",
   "metadata": {},
   "source": [
    "## 一些参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e63f8a-8bbb-4454-937a-516e33330ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "H, W = 64, 64\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370f306a-151e-46dc-9a61-0eea27664de4",
   "metadata": {},
   "source": [
    "## 数据下载与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a61f687-4e5d-47f6-b40b-e286c16830f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ./data\n",
    "if [ ! -d ./data/cifar-10-batches-py ]; then\n",
    "    curl http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz -o ./data/cifar-10-python.tar.gz > /dev/null\n",
    "    tar -xvzf ./data/cifar-10-python.tar.gz -C ./data > /dev/null\n",
    "    rm ./data/cifar-10-python.tar.gz > /dev/null\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "040181ca-73ab-4bfa-84c9-673682a182a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ./data\n",
    "if [ ! -d ./data/tiny-imagenet-200 ]; then\n",
    "    curl https://cs231n.stanford.edu/tiny-imagenet-200.zip -o ./data/tiny-imagenet-200.zip > /dev/null\n",
    "    unzip ./data/tiny-imagenet-200.zip -d ./data > /dev/null\n",
    "    rm ./data/tiny-imagenet-200.zip > /dev/null\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c67b4c8-69aa-4b24-8099-19cfdba6adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import os \n",
    "from os.path import join\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef87006-b908-409c-b35f-f47d87df3094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00355 sec'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义一个计时器，方便后面的使用（这里参考了李沐老师的 D2L 课程）\n",
    "from timer import Timer\n",
    "\n",
    "# Test\n",
    "n = 10000\n",
    "a = np.ones([n])\n",
    "b = np.ones([n])\n",
    "c = np.zeros(n)\n",
    "timer = Timer()\n",
    "for i in range(n):\n",
    "    c[i] = a[i] + b[i]\n",
    "f'{timer.stop():.5f} sec'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa37e7-56c8-45cb-a6dc-4d34016991f1",
   "metadata": {},
   "source": [
    "接下来我么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac6b74b1-9f04-4276-be88-8d77e28b7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集（这里使用的是tiny-imagenet-200 载入了前5个类）\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize(45),\n",
    "    transforms.CenterCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# FileNameEnd = ('.jpeg', '.JPEG', '.tif', '.jpg', '.png', '.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4010b118-06c7-47f6-b125-7e0dafc8dd03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Loader，将数据集砍成 Mini-batch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     12\u001b[0m     val_dataset,\n\u001b[1;32m     13\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     14\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:376\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 376\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/sampler.py:164\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Loader，将数据集砍成 Mini-batch\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(data.shape)\n",
    "    print(target.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4dd65f9-178c-48e6-a7a2-0a7408d9f5e9",
   "metadata": {},
   "source": [
    "## 基础模型：LeNet-5\n",
    "### 正向传播\n",
    "LeNet-5的基本架构如下图所示\n",
    "\n",
    "![image.png](./LeNet-5-Structure.png)\n",
    "\n",
    "`basic_lenet.py`中对其进行了实现，接下来我们测试一下前向传播（为了适配数据集中的200分类，每个卷积层的设计和LeNet完全不同，但大体结构是相似的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5733a13a-e1c2-4c12-8304-14bf5581ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from basic_lenet import BasicLeNet\n",
    "\n",
    "# for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    # net = BasicLeNet()\n",
    "    # net.to(device)\n",
    "    # input_tensor=data.to(device)\n",
    "    # print(input_tensor.shape)\n",
    "    # timer = Timer()\n",
    "    # output = net.forward(input_tensor)\n",
    "    # print(f'{timer.stop():.5f} sec')\n",
    "    # print(output.shape)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a4eb72-8f33-4216-876e-0032f563fc16",
   "metadata": {},
   "source": [
    "### 反向传播与预测实现\n",
    "接下来，我们来实现反向传播与预测（实现同样请见`basic_lenet.py`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54e659-74be-42d3-814a-cce2464a98b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b43d0628",
   "metadata": {},
   "source": [
    "## 对LeNet的微调\n",
    "### 对层架构和层激活函数进行微调\n",
    "我们使用SDG优化器以保证相同的优化器条件下验证不同架构下的训练效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46506cad-bfc1-433e-8d0b-b7a7dcc92a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1/10 ---\n",
      "Train Epoch: 1 [3712/100000 (4%)]\tloss: 6.100099\n",
      "Train Epoch: 1 [7552/100000 (8%)]\tloss: 5.461308\n",
      "Train Epoch: 1 [11392/100000 (11%)]\tloss: 5.470540\n",
      "Train Epoch: 1 [15232/100000 (15%)]\tloss: 5.456755\n",
      "Train Epoch: 1 [19072/100000 (19%)]\tloss: 5.326639\n",
      "Train Epoch: 1 [22912/100000 (23%)]\tloss: 5.158639\n",
      "Train Epoch: 1 [26752/100000 (27%)]\tloss: 5.216241\n",
      "Train Epoch: 1 [30592/100000 (31%)]\tloss: 5.118925\n",
      "Train Epoch: 1 [34432/100000 (34%)]\tloss: 5.141010\n",
      "Train Epoch: 1 [38272/100000 (38%)]\tloss: 5.068676\n",
      "Train Epoch: 1 [42112/100000 (42%)]\tloss: 5.093766\n",
      "Train Epoch: 1 [45952/100000 (46%)]\tloss: 4.927631\n",
      "Train Epoch: 1 [49792/100000 (50%)]\tloss: 4.937091\n",
      "Train Epoch: 1 [53632/100000 (54%)]\tloss: 5.022480\n",
      "Train Epoch: 1 [57472/100000 (57%)]\tloss: 4.829530\n",
      "Train Epoch: 1 [61312/100000 (61%)]\tloss: 4.970461\n",
      "Train Epoch: 1 [65152/100000 (65%)]\tloss: 4.936783\n",
      "Train Epoch: 1 [68992/100000 (69%)]\tloss: 4.940118\n",
      "Train Epoch: 1 [72832/100000 (73%)]\tloss: 4.733409\n",
      "Train Epoch: 1 [76672/100000 (77%)]\tloss: 4.677733\n",
      "Train Epoch: 1 [80512/100000 (80%)]\tloss: 4.803652\n",
      "Train Epoch: 1 [84352/100000 (84%)]\tloss: 4.815100\n",
      "Train Epoch: 1 [88192/100000 (88%)]\tloss: 4.799487\n",
      "Train Epoch: 1 [92032/100000 (92%)]\tloss: 4.729322\n",
      "Train Epoch: 1 [95872/100000 (96%)]\tloss: 4.666576\n",
      "Train Epoch: 1 [99712/100000 (100%)]\tloss: 4.826658\n",
      "Train Loss: 5.0747, Train Accuracy: 2.70%\n",
      "\n",
      "Testing on validation set...\n",
      "\n",
      "Test set: Average loss: 6.8240, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Validation Loss: 6.8240, Validation Accuracy: 0.00%\n",
      "--- Epoch 2/10 ---\n",
      "Train Epoch: 2 [3712/100000 (4%)]\tloss: 4.536168\n",
      "Train Epoch: 2 [7552/100000 (8%)]\tloss: 4.767983\n",
      "Train Epoch: 2 [11392/100000 (11%)]\tloss: 4.554167\n",
      "Train Epoch: 2 [15232/100000 (15%)]\tloss: 4.503531\n",
      "Train Epoch: 2 [19072/100000 (19%)]\tloss: 4.757063\n",
      "Train Epoch: 2 [22912/100000 (23%)]\tloss: 4.753425\n",
      "Train Epoch: 2 [26752/100000 (27%)]\tloss: 4.602276\n",
      "Train Epoch: 2 [30592/100000 (31%)]\tloss: 4.590221\n",
      "Train Epoch: 2 [34432/100000 (34%)]\tloss: 4.547284\n",
      "Train Epoch: 2 [38272/100000 (38%)]\tloss: 4.596982\n",
      "Train Epoch: 2 [42112/100000 (42%)]\tloss: 4.511207\n",
      "Train Epoch: 2 [45952/100000 (46%)]\tloss: 4.626389\n",
      "Train Epoch: 2 [49792/100000 (50%)]\tloss: 4.608459\n",
      "Train Epoch: 2 [53632/100000 (54%)]\tloss: 4.487438\n",
      "Train Epoch: 2 [57472/100000 (57%)]\tloss: 4.544321\n",
      "Train Epoch: 2 [61312/100000 (61%)]\tloss: 4.568544\n",
      "Train Epoch: 2 [65152/100000 (65%)]\tloss: 4.617655\n",
      "Train Epoch: 2 [68992/100000 (69%)]\tloss: 4.506188\n",
      "Train Epoch: 2 [72832/100000 (73%)]\tloss: 4.555078\n",
      "Train Epoch: 2 [76672/100000 (77%)]\tloss: 4.429786\n",
      "Train Epoch: 2 [80512/100000 (80%)]\tloss: 4.473826\n",
      "Train Epoch: 2 [84352/100000 (84%)]\tloss: 4.410799\n",
      "Train Epoch: 2 [88192/100000 (88%)]\tloss: 4.601104\n",
      "Train Epoch: 2 [92032/100000 (92%)]\tloss: 4.498687\n",
      "Train Epoch: 2 [95872/100000 (96%)]\tloss: 4.425868\n",
      "Train Epoch: 2 [99712/100000 (100%)]\tloss: 4.590156\n",
      "Train Loss: 4.5863, Train Accuracy: 6.55%\n",
      "\n",
      "Testing on validation set...\n",
      "\n",
      "Test set: Average loss: 7.2714, Accuracy: 6/10000 (0%)\n",
      "\n",
      "Validation Loss: 7.2714, Validation Accuracy: 0.06%\n",
      "--- Epoch 3/10 ---\n",
      "Train Epoch: 3 [3712/100000 (4%)]\tloss: 4.320779\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     24\u001b[0m     train_accuracies\u001b[38;5;241m.\u001b[39mappend(train_acc)\n",
      "File \u001b[0;32m~/class_project/LeNet-5-Optimism/basic_resnet50.py:111\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m    108\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m--> 111\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), \u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    113\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c52e8-370f-4c7b-a3fa-be629590e6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19581f09-6c1b-4a37-8cb8-69facec010a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0af408-241c-47da-b2e5-d6c832992b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e329294a-0b5e-4a8d-9351-575c016f4140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
